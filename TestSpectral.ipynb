{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:80: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:91: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:91: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:96: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:80: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:91: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:91: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:96: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-125-d3d55cb76bcf>:80: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if visited[i] is 0:\n",
      "<ipython-input-125-d3d55cb76bcf>:91: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.map[w][k] is 1 and visited[k] is 0:\n",
      "<ipython-input-125-d3d55cb76bcf>:91: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if self.map[w][k] is 1 and visited[k] is 0:\n",
      "<ipython-input-125-d3d55cb76bcf>:96: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if visited[i] is 0:\n"
     ]
    }
   ],
   "source": [
    "class Graph:\n",
    "    def __init__(self, maps, edgenum=0):\n",
    "        self.map = maps\n",
    "        self.nodenum = len(maps)\n",
    "        self.edgenum = edgenum\n",
    "        self.W = np.zeros((len(maps), len(maps)))#maps\n",
    "        self.path = np.zeros((len(maps), len(maps)))\n",
    "        self.W_Bellman_Ford = np.zeros((len(maps), len(maps)))\n",
    "        self.path_Bellman_Ford = np.zeros((len(maps), len(maps)))\n",
    "        self.edge = []\n",
    "        e = []\n",
    "        for i in range(self.nodenum):\n",
    "            for j in range(self.nodenum):\n",
    "                if(self.map[i][j] != 0):\n",
    "                    e.append(i)\n",
    "                    e.append(j)\n",
    "                    e.append(self.map[i][j])\n",
    "                    e1 = e[:] \n",
    "                    self.edge.append(e1)\n",
    "                e[:] = []\n",
    "\n",
    "    def isOutRange(self, x):\n",
    "        try:\n",
    "            if x >= self.nodenum or x <= 0:\n",
    "                raise IndexError\n",
    "        except IndexError:\n",
    "            print(\"We have errors everyday, don't worry, check index again!\")\n",
    "\n",
    "    def GetNodenum(self):\n",
    "        self.nodenum = len(self.map)\n",
    "        return self.nodenum\n",
    "\n",
    "    def GetEdgenum(self):\n",
    "        self.edgenum = 0\n",
    "        for i in range(self.nodenum):\n",
    "            for j in range(self.nodenum):\n",
    "                if self.map[i][j] != 0:\n",
    "                    self.edgenum = self.edgenum + 1\n",
    "        return self.edgenum\n",
    "\n",
    "    def InsertNode(self):\n",
    "        for i in range(self.nodenum):\n",
    "            self.map[i].append(0)\n",
    "            self.W[i].append(0)\n",
    "            self.path.append(0)\n",
    "        self.nodenum = self.nodenum + 1\n",
    "        ls = [0] * self.nodenum\n",
    "        self.map.append(ls)\n",
    "        self.W.append(ls)\n",
    "        self.path.append(ls)\n",
    "\n",
    "    def DeleteNode(self, x):\n",
    "        for i in range(self.nodenum):\n",
    "            if self.map[i][x] != 0:\n",
    "                self.map[i][x] = 0\n",
    "                self.edgenum = self.edgenum - 1\n",
    "            if self.map[x][i] != 0:\n",
    "                self.map[x][i] = 0\n",
    "                self.edgenum = self.edgenum - 1\n",
    "\n",
    "    def AddEdge(self, x, y):\n",
    "        if self.map[x][y] != 1:\n",
    "            self.map[x][y] = 1\n",
    "            self.edgenum = self.edgenum + 1\n",
    "\n",
    "    def RemoveEdge(self, x, y):\n",
    "        if self.map[x][y] != 0:\n",
    "            self.map[x][y] = 0\n",
    "            self.edgenum = self.edgenum - 1\n",
    "\n",
    "    def BreadthFirstSearch(self):\n",
    "        def BFS(self, i):\n",
    "            print(i)\n",
    "            visited[i] = 1\n",
    "            for k in range(self.nodenum):\n",
    "                if self.map[i][k] == 1 and visited[k] == 0:\n",
    "                    BFS(self, k)\n",
    "        visited = [0] * self.nodenum\n",
    "        for i in range(self.nodenum):\n",
    "            if visited[i] is 0:\n",
    "                BFS(self, i)\n",
    "\n",
    "    def DepthFirstSearch(self):\n",
    "        def DFS(self, i, queue):\n",
    "            queue.append(i)\n",
    "            print(i)\n",
    "            visited[i] = 1\n",
    "            if len(queue) != 0:\n",
    "                w = queue.pop()\n",
    "                for k in range(self.nodenum):\n",
    "                    if self.map[w][k] is 1 and visited[k] is 0:\n",
    "                        DFS(self, k, queue)\n",
    "        visited = [0] * self.nodenum\n",
    "        queue = []\n",
    "        for i in range(self.nodenum):\n",
    "            if visited[i] is 0:\n",
    "                DFS(self, i, queue)\n",
    "\n",
    "    def K_Nearest_Neighbor_Similarity_Matrix_Computr(self, k):\n",
    "        remain = [0] * k\n",
    "        for row in range(self.nodenum):\n",
    "            for i in range(k):\n",
    "                remain[i] = row + i +1\n",
    "            min_index = remain[0]\n",
    "            for j in range(1, k):\n",
    "                if(self.map[row][remain[j]] <= self.map[row][remain[0]]):\n",
    "                    min_index = remain[j]\n",
    "            col = row + k + 1\n",
    "            while col%self.nodenum != row:\n",
    "                if(self.map[row][col] > self.map[row][min_index]):\n",
    "                    self.map[row][min_index] = 0\n",
    "                    min_index = col\n",
    "\n",
    "                    for j in range(k):\n",
    "                        if(self.map[row][remain[j]] <= self.map[row][min_index]):\n",
    "                            min_index = remain[j]\n",
    "                else:\n",
    "                    self.map[row][col] = 0\n",
    "\n",
    "        for row in range(self.nodenum):\n",
    "            for col in range(self.nodenum):\n",
    "                if(self.map[row][col] != self.map[col][row]):\n",
    "                    if(self.map[row][col] != 0):\n",
    "                        self.map[col][row] = self.map[row][col]\n",
    "                    if(self.map[col][row] != 0):\n",
    "                        self.map[row][col] = self.map[col][row]\n",
    "        pass\n",
    "\n",
    "    def Bellman_Ford(self, original):\n",
    "        for i in range(self.nodenum):\n",
    "            if i == original:\n",
    "                self.W_Bellman_Ford[original][i] = 0\n",
    "            else:\n",
    "                self.W_Bellman_Ford[original][i] = 1000000 # max\n",
    "            if self.map[original][i] != 0:\n",
    "                self.W_Bellman_Ford[original][i] = self.map[original][i]\n",
    "                self.path_Bellman_Ford[original][i] = original\n",
    "            else:\n",
    "                self.path_Bellman_Ford[original][i] = -1\n",
    "\n",
    "        for j in range(self.nodenum):\n",
    "            flag_end = False\n",
    "            for e in range(len(self.edge)):\n",
    "                if self.W_Bellman_Ford[original][(self.edge[e])[1]] > self.W_Bellman_Ford[original][(self.edge[e])[0]] + (self.edge[e])[2]:\n",
    "                    self.W_Bellman_Ford[original][(self.edge[e])[1]] = self.W_Bellman_Ford[original][(self.edge[e])[0]] + (self.edge[e])[2]\n",
    "                    self.path_Bellman_Ford[original][(self.edge[e])[1]] = (self.edge[e])[0]\n",
    "                    flag_end = True\n",
    "            if(flag_end == False):\n",
    "                break\n",
    "\n",
    "        flag = True \n",
    "        for e1 in range(len(self.edge)):\n",
    "            if self.W_Bellman_Ford[original][(self.edge[e1])[1]] > self.W_Bellman_Ford[original][(self.edge[e1])[0]] + (self.edge[e1])[2]:\n",
    "                flag = False\n",
    "                break\n",
    "        return flag\n",
    "    \n",
    "    def SimilarityMatrix(self):\n",
    "        for row in range(self.nodenum):\n",
    "            for col in range(self.nodenum):\n",
    "                self.W[row][col] = self.map[row][col]\n",
    "                if(self.map[row][col] != 0 and row != col):\n",
    "                    self.path[row][col] = row\n",
    "                else:\n",
    "                    self.path[row][col] = -1\n",
    "        for k in range(self.nodenum):\n",
    "            for i in range(self.nodenum):\n",
    "                for j in range(self.nodenum):\n",
    "                    if(self.W[i][k] != 0 and self.W[k][j] != 0):\n",
    "                        if((self.W[i][k] + self.W[k][j] < self.W[i][j]) or (self.W[i][j] == 0 and i != j)): # 0表示不通或者无穷大\n",
    "                            self.W[i][j] = self.W[i][k] + self.W[k][j]\n",
    "                            self.path[i][j] = self.path[k][j]\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWbyKNN(dis_matrix, k):\n",
    "        print(type(dis_matrix))\n",
    "        W = np.zeros((len(dis_matrix), len(dis_matrix)))\n",
    "        for idx,each in enumerate(dis_matrix):\n",
    "            index_array  = np.argsort(each)\n",
    "            for i in index_array[1:k+1]:\n",
    "                W[idx][i] = dis_matrix[idx][i] \n",
    "        tmp_W = np.transpose(W)\n",
    "        W = (tmp_W+W)/2 \n",
    "        return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x, y):\n",
    "    return  np.linalg.norm(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Degree matrix \n",
    "def degreeMatrix(W):\n",
    "    points_num = len(W)\n",
    "    D = np.diag(np.zeros(points_num))\n",
    "    for i in range(points_num):\n",
    "        D[i][i] = sum(W[i])\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigenvector(L, cluster_num):\n",
    "    eigval,eigvec = np.linalg.eig(L)\n",
    "    dim = len(eigval)\n",
    "    dictEigval = dict(zip(eigval,range(0,dim)))\n",
    "    kEig = np.sort(eigval)[0:cluster_num]\n",
    "    ix = [dictEigval[k] for k in kEig]\n",
    "    return eigval[ix],eigvec[:,ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimilarityMatrix(W):\n",
    "        M = np.zeros((len(W), len(W)))\n",
    "        for i in range(len(W)):\n",
    "            for j in range(len(W)):\n",
    "                if W[i][j] != 0:\n",
    "                    M[i][j] = 1 / W[i][j]\n",
    "        return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpectralClustering():\n",
    "\n",
    "    maps = [\n",
    "        [0, 3, 5, 8, 0],\n",
    "        [3, 0, 6, 4, 11],\n",
    "        [5, 6, 0, 2, 0],\n",
    "        [8, 4, 2, 0, 10],\n",
    "        [0, 11, 0, 10, 0]\n",
    "    ]\n",
    "    \n",
    "    G = Graph(maps)\n",
    "    print(G.map)\n",
    "    G.SimilarityMatrix()\n",
    "    W1 = G.W\n",
    "    print(W1)\n",
    "    path = G.path\n",
    "    print(path)\n",
    "\n",
    "    M = SimilarityMatrix(W1)\n",
    "\n",
    "    W = getWbyKNN(M, 2)             # k=2\n",
    "    D = getD(W)\n",
    "    print(W)\n",
    "    print(D)\n",
    "\n",
    "    # Laplacian\n",
    "    L = D - W\n",
    "    cluster_num = 3                 # cluster = 3\n",
    "\n",
    "    eigval, eigvec = eigenvector(L, cluster_num)\n",
    "\n",
    "    clf = KMeans(n_clusters=cluster_num)\n",
    "    s = clf.fit(eigvec)\n",
    "    C = s.labels_\n",
    "    print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DoTest():\n",
    "    maps = [\n",
    "        [0, 3, 5, 8, 0],\n",
    "        [3, 0, 8, 4, 11],\n",
    "        [5, 6, 0, 2, 0],\n",
    "        [8, 4, 2, 0, 10],\n",
    "        [0, 11, 0, 10 , 0]\n",
    "        ]\n",
    "    G = Graph(maps)\n",
    "    print(G.map)\n",
    "    G.SimilarityMatrix()\n",
    "    W = G.W\n",
    "    path = G.path\n",
    "    print(path)\n",
    "    print(W)\n",
    "\n",
    "    for i in range(G.nodenum):\n",
    "        G.Bellman_Ford(i)\n",
    "    W1 = G.W_Bellman_Ford\n",
    "    path1 = G.path_Bellman_Ford\n",
    "    print(W1)\n",
    "    print(path1)\n",
    "    M = SimilarityMatrix(W)\n",
    "    print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 3, 5, 8, 0], [3, 0, 8, 4, 11], [5, 6, 0, 2, 0], [8, 4, 2, 0, 10], [0, 11, 0, 10, 0]]\n",
      "[[-1.  0.  0.  1.  1.]\n",
      " [ 1. -1.  3.  1.  1.]\n",
      " [ 2.  2. -1.  2.  3.]\n",
      " [ 1.  3.  3. -1.  3.]\n",
      " [ 1.  4.  3.  4. -1.]]\n",
      "[[ 0.  3.  5.  7. 14.]\n",
      " [ 3.  0.  6.  4. 11.]\n",
      " [ 5.  6.  0.  2. 12.]\n",
      " [ 7.  4.  2.  0. 10.]\n",
      " [14. 11. 12. 10.  0.]]\n",
      "[[ 0.  3.  5.  7. 14.]\n",
      " [ 3.  0.  6.  4. 11.]\n",
      " [ 5.  6.  0.  2. 12.]\n",
      " [ 7.  4.  2.  0. 10.]\n",
      " [14. 11. 12. 10.  0.]]\n",
      "[[-1.  0.  0.  1.  1.]\n",
      " [ 1. -1.  3.  1.  1.]\n",
      " [ 2.  2. -1.  2.  3.]\n",
      " [ 1.  3.  3. -1.  3.]\n",
      " [ 1.  4.  3.  4. -1.]]\n",
      "[[0.         0.33333333 0.2        0.14285714 0.07142857]\n",
      " [0.33333333 0.         0.16666667 0.25       0.09090909]\n",
      " [0.2        0.16666667 0.         0.5        0.08333333]\n",
      " [0.14285714 0.25       0.5        0.         0.1       ]\n",
      " [0.07142857 0.09090909 0.08333333 0.1        0.        ]]\n"
     ]
    }
   ],
   "source": [
    "DoTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAsk professor\\n1. about complexity clustering algos, hierarchical clustering/spectral clustering/kmeans/divisive\\n2. time processing\\n3. the kmeans algorithm could be modified to generate more than one random mean for each cluster,\\nallowing it to run in multiple threads at the same time?\\n4. could or couldn\\'t initialize graph like a \"class\"\\n5. Closed neighborhood similarity or Dijsktra\\n'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ask professor\n",
    "1. about complexity clustering algos, hierarchical clustering/spectral clustering/kmeans/divisive\n",
    "2. time processing\n",
    "3. the kmeans algorithm could be modified to generate more than one random mean for each cluster,\n",
    "allowing it to run in multiple threads at the same time?\n",
    "4. could or couldn't initialize graph like a \"class\"\n",
    "5. Closed neighborhood similarity or Dijsktra\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 3, 5, 8, 0], [3, 0, 6, 4, 11], [5, 6, 0, 2, 0], [8, 4, 2, 0, 10], [0, 11, 0, 10, 0]]\n",
      "[[ 0.  3.  5.  7. 14.]\n",
      " [ 3.  0.  6.  4. 11.]\n",
      " [ 5.  6.  0.  2. 12.]\n",
      " [ 7.  4.  2.  0. 10.]\n",
      " [14. 11. 12. 10.  0.]]\n",
      "[[-1.  0.  0.  1.  1.]\n",
      " [ 1. -1.  1.  1.  1.]\n",
      " [ 2.  2. -1.  2.  3.]\n",
      " [ 1.  3.  3. -1.  3.]\n",
      " [ 1.  4.  3.  4. -1.]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[0.         0.         0.         0.14285714 0.07142857]\n",
      " [0.         0.         0.16666667 0.         0.04545455]\n",
      " [0.         0.16666667 0.         0.         0.08333333]\n",
      " [0.14285714 0.         0.         0.         0.05      ]\n",
      " [0.07142857 0.04545455 0.08333333 0.05       0.        ]]\n",
      "[[0.21428571 0.         0.         0.         0.        ]\n",
      " [0.         0.21212121 0.         0.         0.        ]\n",
      " [0.         0.         0.25       0.         0.        ]\n",
      " [0.         0.         0.         0.19285714 0.        ]\n",
      " [0.         0.         0.         0.         0.25021645]]\n",
      "[0 1 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "SpectralClustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
